# Report: Describing trends

**Function file:** `describing-trends`
**Source paper:** `2211.05100`

---

## 1. Original templates (phrasebank)

*Source: https://www.phrasebank.manchester.ac.uk/describing-trends/*

### Highlighting a trend in a table or chart

- What is striking What stands out What is interesting What can be clearly seen in this table chart figure is the growth of …
- is the high rate of …
- is the variability of …
- is the dominance of …
- is the rapid decrease in …
- is the steady decline of …
- is the general pattern of …
- is the dramatic decline in …
- is the continual growth of …
- is the difference between …
- is the phenomenal growth of …
- What is striking What stands out What is interesting What can be clearly seen | in this | table chart figure | is the growth of …
- Describing high and low points in figures Production of X peaked in 1985. X rose to a high point and peaked in …
- The peak age for committing a crime is 18. The number of Xs reached a peak during …
- Production of X reached a low point in 1990. The rate fell to a low point of $5.00 at the end of the year.

### Describing high and low points in figures

- Production of X peaked in 1985. X rose to a high point and peaked in …
- The peak age for committing a crime is 18. The number of Xs reached a peak during …
- Production of X reached a low point in 1990. The rate fell to a low point of $5.00 at the end of the year.
- Production of X reached a low point in 1990. The rate fell to a low point of $5.00 at the end of the year.
- increase level off decline by …
- drop sharply remain steady be as high as …
- decline steadily continue decreasing grow by more than …

### Projecting trends

- The rate of X The amount of X The number of Xs is likely to will probably is expected to is projected to fall fall reach …
- increase level off decline by …
- drop sharply remain steady be as high as …
- decline steadily continue decreasing grow by more than …
- after 2035.
- | after 2035.

---

## 2. Similar sentences found in the paper

- Pretrained language models have become a cornerstone of modern natural language processing (NLP) pipelines because they often produce better performance from smaller quantities of labeled data.
- The subsequent finding that pretrained language models can perform useful tasks without any additional training (Radford et al., 2019; Brown et al., 2020) further demonstrated their utility.
- In addition, the empirical observation that a language model’s performance tends to increase as the model is made larger—sometimes predictably (Hestness et al., 2017; Kaplan et al., 2020; Hoffmann et al., 2022) and sometimes suddenly (Wei et al., 2022)—has led to a trend of increasing scale (Zeng et al., 2021; Rae et al., 2021; Smith et al., 2022; Chowdhery et al., 2022).
- Notably, Radford et al. (2019) found that performance improved with model scale, inspiring work to characterize (Kaplan et al., 2020; Hoffmann et al., 2022) and exploit (Shoeybi et al., 2019; Brown et al., 2020; Smith et al., 2022; Chowdhery et al., 2022; Rae et al., 2021; Wang et al., 2021; Zeng et al., 2021; Zhang et al., 2022) the benefits of scale.
- While most attempts to estimate the carbon footprint of language models have shed light on the emissions produced due to energy consumed during model training (e.g. Patterson et al., 2021; Strubell et al., 2019), other sources of emissions are also important to consider.
- Comparing the carbon emissions of BLOOM training to other similar models (see Table 4), reveals that while the energy consumption of BLOOM is slightly higher than OPT (Zhang et al., 2022) (433 Mwh compared to OPT’s 324 MWh), its emissions are approximately 2/3 less (25 tons versus 70 tons).
- The translation quality for many of the low-resource languages is good, comparable to or even slightly better than the supervised M2M model.
- However, results are very poor between Swahili and Yoruba, languages that are present but under-represented in BLOOM’s training data (<<<50k tokens each).
- We also discuss evaluation results of BLOOM and other large language models, finding it has competitive performance that improves after multitask finetuning.
- The following contains prompts used for evaluation.

---

## 3. Source of the paper

- File: `2211.05100.html`
- Path: `/Users/simonwang/Library/CloudStorage/OneDrive-HongKongBaptistUniversity/GTD/Areas/Teaching/Courses/MCCP 6020/PhDagentSpring2026/writing/buildPaperCollection_arXiv/html_collection/2211.05100.html`

---

## 4. New template extracted from the paper

- Pretrained language models have become a cornerstone of X because they often produce better performance from Y.
- The finding that pretrained language models can perform useful tasks without any additional training further demonstrated their utility.
- The empirical observation that a language model’s performance tends to increase as the model is made larger has led to a trend of increasing scale.
- Notably, performance improved with model scale, inspiring work to characterize and exploit the benefits of scale.
- While most attempts to estimate the carbon footprint of X have shed light on the emissions produced due to Y, other sources of emissions are also important to consider.
- Comparing the carbon emissions of X to other similar models reveals that while the energy consumption of X is slightly higher than Y, its emissions are approximately Z less.
- The translation quality for many of the low-resource languages is good, comparable to or even slightly better than the supervised model.
- However, results are very poor between X and Y, languages that are present but under-represented in Z’s training data.
- We also discuss evaluation results of X, finding it has competitive performance that improves after Y.
- The following contains prompts used for evaluation for X.
