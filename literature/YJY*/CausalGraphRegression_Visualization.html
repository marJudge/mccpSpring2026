<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Causal Graph Regression — Macro-Level Structure</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
        h1 { text-align: center; color: #2c3e50; margin-bottom: 30px; }
        .structure-diagram { display: flex; flex-direction: column; gap: 20px; }
        .section { border: 2px solid #3498db; border-radius: 8px; padding: 15px; background: #ecf0f1; position: relative; }
        .section-header { background: #3498db; color: white; padding: 10px; margin: -15px -15px 15px -15px; border-radius: 6px 6px 0 0; display: flex; justify-content: space-between; align-items: center; }
        .section-title { font-weight: bold; font-size: 1.2em; }
        .word-count { font-size: 0.9em; opacity: 0.9; }
        .moves { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 10px; margin-top: 10px; }
        .move { background: white; padding: 10px; border-radius: 5px; border-left: 4px solid #e74c3c; }
        .move-title { font-weight: bold; color: #e74c3c; margin-bottom: 5px; }
        .move-content { font-size: 0.9em; color: #555; }
        .key-excerpt { background: #fff3cd; border: 1px solid #ffeaa7; border-radius: 5px; padding: 10px; margin: 10px 0; font-style: italic; }
        .analysis { background: #d4edda; border: 1px solid #c3e6cb; border-radius: 5px; padding: 10px; margin: 10px 0; font-size: 0.9em; }
        .flow-arrow { text-align: center; font-size: 2em; color: #7f8c8d; margin: 10px 0; }
        .comparison-table { width: 100%; border-collapse: collapse; margin: 20px 0; background: white; }
        .comparison-table th, .comparison-table td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        .comparison-table th { background-color: #f2f2f2; font-weight: bold; }
        .highlight { background-color: #fff3cd; font-weight: bold; }
        .legend { background: #ecf0f1; padding: 15px; border-radius: 5px; margin: 20px 0; }
        .legend-item { display: inline-block; margin: 5px 15px 5px 0; padding: 5px 10px; border-radius: 3px; font-size: 0.9em; }
        .cs-convention { background: #3498db; color: white; }
        .traditional { background: #e74c3c; color: white; }
        .universal { background: #27ae60; color: white; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Causal Graph Regression — Macro-Level Structure</h1>
        <p><strong>Paper:</strong> A Recipe for Causal Graph Regression: Confounding Effects Revisited. <strong>Authors:</strong> Yujia Yin, Tianyi Qu, Zihao Wang, Yifan Chen. <strong>Venue:</strong> ICML 2025 (PMLR 267). <strong>Field:</strong> ML / GNNs / Causal Learning / OOD.</p>

        <div class="legend">
            <h3>Analysis Framework</h3>
            <div class="legend-item cs-convention">ML / GNN Convention</div>
            <div class="legend-item traditional">Traditional Academic</div>
            <div class="legend-item universal">Universal Best Practice</div>
        </div>

        <div class="structure-diagram">

            <div class="section">
                <div class="section-header">
                    <span class="section-title">Section 1: Introduction</span>
                    <span class="word-count">~600 words</span>
                </div>
                <div class="moves">
                    <div class="move">
                        <div class="move-title">Move 1: Establishing Territory</div>
                        <div class="move-content"><strong>Centrality:</strong> CGL for OOD; drug discovery, climate. Causal vs. confounding (C, S, Y).</div>
                        <div class="key-excerpt">"Causal graph learning (CGL) holds particular importance due to its relevance in fields such as drug discovery and climate modeling. Causal features C directly decide Y; confounding S presents spurious correlations."</div>
                        <div class="analysis">SCM (Figure 1) sets up C vs. S. Applications establish importance.</div>
                    </div>
                    <div class="move">
                        <div class="move-title">Move 2: Establishing Niche</div>
                        <div class="move-content"><strong>Gaps:</strong> CGL = classification-only; regression overlooked. Confounders assumed non-predictive (e.g. molecular weight vs. toxicity).</div>
                        <div class="key-excerpt">"A systematical understanding of how CGL techniques should be adapted to graph-level regression is still under-explored."</div>
                        <div class="key-excerpt">"Existing CGL methods... are built on a strong assumption that confounding subgraphs contain strictly no predictive power... molecular weight is noncausal to toxicity while does exhibit strong correlations."</div>
                        <div class="analysis">Two gaps: regression underexplored; confounder assumption unrealistic.</div>
                    </div>
                    <div class="move">
                        <div class="move-title">Move 3: Occupying Niche</div>
                        <div class="move-content"><strong>Solution:</strong> Enhanced GIB + contrastive intervention. Three contributions.</div>
                        <div class="key-excerpt">"We develop an enhanced GIB loss... generalize [intervention] from class separation to instance discrimination... contrastive learning... (1) First to consider predictive role of confounders in graph regression; (2) New intervention via CL; (3) SOTA on OOD benchmarks."</div>
                        <div class="analysis">Explicit contributions; CL bridges classification→regression.</div>
                    </div>
                </div>
            </div>

            <div class="flow-arrow">↓</div>

            <div class="section">
                <div class="section-header">
                    <span class="section-title">Section 2: Related Work</span>
                    <span class="word-count">~500 words</span>
                </div>
                <div class="moves">
                    <div class="move">
                        <div class="move-title">Thematic Overview</div>
                        <div class="move-content"><strong>Taxonomy:</strong> Invariant learning (CIGA, GSAT, GALA); causal (CAL, DisC, etc.); stable learning.</div>
                        <div class="key-excerpt">"Existing approaches can be broadly categorized into invariant learning, causal modeling, and stable learning."</div>
                    </div>
                    <div class="move">
                        <div class="move-title">Critical Analysis</div>
                        <div class="move-content"><strong>Limitations:</strong> Classification-focused; post-hoc only; confounders disregarded; regression-specific challenges.</div>
                        <div class="key-excerpt">"However, they often disregard the predictive potential of confounding features... the supervised loss functions tailored for classification tasks are not easily adaptable to regression problems."</div>
                        <div class="analysis">Gaps via systematic critique per category.</div>
                    </div>
                </div>
            </div>

            <div class="flow-arrow">↓</div>

            <div class="section">
                <div class="section-header">
                    <span class="section-title">Section 3: Preliminaries (3.1–3.3)</span>
                    <span class="word-count">~400 words</span>
                </div>
                <div class="moves">
                    <div class="move">
                        <div class="move-title">CGL, GIB, Intervention</div>
                        <div class="move-content"><strong>C:</strong> C := (M⊙A, M·X); S := G−C. <strong>GIB:</strong> −I(C;Y)+αI(C;G). <strong>Backdoor:</strong> P(Y|do(C)) via P(Y|C,S).</div>
                        <div class="key-excerpt">"The GIB objective is −I(C; Y) + αI(C; G). Backdoor adjustment... estimate P(Y|do(C)) by stratifying over S."</div>
                        <div class="analysis">Formal setup for enhanced GIB and contrastive intervention.</div>
                    </div>
                </div>
            </div>

            <div class="flow-arrow">↓</div>

            <div class="section">
                <div class="section-header">
                    <span class="section-title">Section 4: Method (4.1–4.3)</span>
                    <span class="word-count">~1200 words</span>
                </div>
                <div class="moves">
                    <div class="move">
                        <div class="move-title">4.1 Overview</div>
                        <div class="move-content"><strong>Pipeline:</strong> GNN → masks → C, S → G_c, G_s → readouts. L_GIB + L_CI.</div>
                        <div class="key-excerpt">"Enhanced GIB loss L_GIB... counterfactual samples H_mix... contrastive-learning-based causal intervention loss L_CI."</div>
                    </div>
                    <div class="move">
                        <div class="move-title">4.2 Enhanced GIB</div>
                        <div class="move-content"><strong>Extension:</strong> −I(C;Y)+αI(C;G)−βI(S;Y). Model predictive role of S.</div>
                        <div class="key-excerpt">"Our enhanced GIB objective: −I(C; Y) + αI(C; G) − βI(S; Y)... capture the predictive capacity of S."</div>
                        <div class="analysis">Relaxes "confounders non-predictive" assumption.</div>
                    </div>
                    <div class="move">
                        <div class="move-title">4.3 Contrastive Intervention</div>
                        <div class="move-content"><strong>H_mix = H_c + H_s;</strong> positive (H_g, H_mix), negatives other graphs. L = L_GIB + λ L_CI.</div>
                        <div class="key-excerpt">"Learning causal representations through contrastive learning... causal subgraph invariant across varying confounders. L = L_GIB + λ L_CI."</div>
                        <div class="analysis">Instance discrimination replaces label-dependent intervention.</div>
                    </div>
                </div>
            </div>

            <div class="flow-arrow">↓</div>

            <div class="section">
                <div class="section-header">
                    <span class="section-title">Section 5: Experiments (5.1–5.5)</span>
                    <span class="word-count">~1500 words</span>
                </div>
                <div class="moves">
                    <div class="move">
                        <div class="move-title">Datasets & Baselines</div>
                        <div class="move-content"><strong>GOOD-ZINC</strong> (Scaffold/Size × Covariate/Concept); <strong>ReactionOOD</strong> (Cycloaddition, RDB7, E2&SN2). ERM, IRM, VREx, CIGA, GSAT, DIR, etc.</div>
                    </div>
                    <div class="move">
                        <div class="move-title">GOOD-ZINC Results</div>
                        <div class="move-content"><strong>SOTA</strong>; large gains over GSAT. Lower variance.</div>
                        <div class="key-excerpt">"Our method achieves SOTA on GOOD-ZINC... outperforming GSAT by 42.2% (ID) and 26.3% (OOD) in Scaffold Covariate; 29.0% and 48.1% in Concept. Significantly reduced variances."</div>
                    </div>
                    <div class="move">
                        <div class="move-title">ReactionOOD & Ablation</div>
                        <div class="move-content">Best or 2nd in 6/10 OOD cases; RDB7 best concept shift. Ablation: predictive confounders + L_CI both crucial.</div>
                        <div class="key-excerpt">"Best OOD in 6/10 cases... Ignoring predictive role of confounders → weaker OOD. Contrastive intervention effective in classification too."</div>
                        <div class="analysis">Generalizability; ablations support design choices.</div>
                    </div>
                </div>
            </div>

        </div>

        <h2>Cross-Disciplinary Comparison</h2>
        <table class="comparison-table">
            <tr>
                <th>Aspect</th>
                <th>This Paper (ML / GNN)</th>
                <th>Traditional Academic</th>
                <th>Key Learning</th>
            </tr>
            <tr>
                <td>Literature Review</td>
                <td class="highlight">Dedicated section; invariant / causal / stable taxonomy</td>
                <td>Often in introduction</td>
                <td>Structured critique by category</td>
            </tr>
            <tr>
                <td>Technical Detail</td>
                <td class="highlight">High (GIB, SCM, variational bounds, losses)</td>
                <td>Medium</td>
                <td>Formal objectives and loss decomposition</td>
            </tr>
            <tr>
                <td>Evaluation</td>
                <td class="highlight">OOD benchmarks, multiple shifts, ablations</td>
                <td>Theoretical / limited empirical</td>
                <td>Breadth and ablations</td>
            </tr>
            <tr>
                <td>Contribution Claims</td>
                <td class="highlight">Method + empirical validation; code available</td>
                <td>Theoretical + evidence</td>
                <td>Reproducibility and scope</td>
            </tr>
        </table>

        <h2>Imitation Framework for Future Papers</h2>
        <div class="analysis">
            <h3>Structural Elements to Adapt</h3>
            <ul>
                <li><strong>Assumption critique:</strong> "Prior work assumes X; we argue X is unrealistic because …"</li>
                <li><strong>Enhanced objective:</strong> Extend standard formulation with interpretable new terms</li>
                <li><strong>Contrastive intervention:</strong> Replace label-dependent intervention for regression</li>
                <li><strong>Two-part loss:</strong> L_GIB + λ L_CI; clear roles</li>
            </ul>
            <h3>Rhetorical Strategies</h3>
            <ul>
                <li><strong>"To the best of our knowledge":</strong> First to consider predictive confounders in graph regression</li>
                <li><strong>Explicit contributions:</strong> Numbered bullets</li>
                <li><strong>Benchmark diversity:</strong> Multiple OOD types; acknowledge "no single winner"</li>
            </ul>
            <h3>Quality Indicators</h3>
            <ul>
                <li><strong>Formal clarity:</strong> SCM, GIB, loss equations</li>
                <li><strong>Empirical coverage:</strong> ID/OOD, ablations, classification transfer</li>
                <li><strong>Code:</strong> Public implementation</li>
            </ul>
        </div>

        <div style="text-align: center; margin-top: 30px; color: #7f8c8d; font-size: 0.9em;">
            <p>Analysis based on macro-level structure framework (activity 1.2). Visual scaffold for paper organization.</p>
        </div>
    </div>
</body>
</html>
